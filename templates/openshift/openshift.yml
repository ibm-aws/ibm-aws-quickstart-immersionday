AWSTemplateFormatVersion: '2010-09-09'
Description: Template for an self-managed Openshift deployment.
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label: 
          default: Cluster Configuration
        Parameters:
          - ClusterName
          - DomainName
          - PrivateCluster
          - RedhatPullSecret
          - OpenshiftVersion
          - EnableFips
      - Label: 
          default: ControlPlane configuration
        Parameters:
          - MasterInstanceType
          - MasterVolumeIOPS
          - MasterVolumeSize
          - MasterVolumeType
      - Label: 
          default: Worker configuration
        Parameters:
          - WorkerInstanceType
          - WorkerVolumeIOPS
          - WorkerVolumeSize
          - WorkerVolumeType
          - WorkerCount
      - Label: 
          default: OCS/ODF Storage configuration
        Parameters:
          - OcsInstanceType
          - OcsIOPS
          - OcsVolumeSize
          - OcsVolumeType
      - Label:
          default: AZ
        Parameters:
          - NumberOfAZs
          - AvailabilityZones
      - Label: 
          default: Networking
        Parameters:
          - VPCID
          - PrivateSubnet1ID
          - PrivateSubnet2ID
          - PrivateSubnet3ID
          - PublicSubnet1ID
          - PublicSubnet2ID
          - PublicSubnet3ID
          - BootNodeAccessCIDR
      - Label: 
          default: Cluster Networking
        Parameters:
          - ClusterNetworkCIDR
          - ClusterNetowrkHostPrefix
          - MachineNetworkCIDR
          - ServiceNetworkCIDR
      - Label: 
          default: Instance Configuration
        Parameters:
          - KeyPairName

Parameters:
  ClusterName:
    Default: "os-d01"
    Description: Custom cluster name for kubernetes.io/cluster/tags.
    Type: String
    AllowedPattern: ^[0-9a-z-]*$
  DomainName:
    Description: 'Amazon Route53 base domain configured for your OpenShift Container Platform cluster. Name must consist of lower case alphanumeric characters and must start and end with an alphanumeric character.'
    Type: String
    Default: "ibmworkshops.com"
  PrivateCluster:  
    Description: To Deploy a Private cluster select true and false for Public cluster
    Type: String
    AllowedValues:
      - "True"
      - "False"
    Default: "False"
  RedhatPullSecret:
    Description: Your Red Hat Network (RHN) pull secret(e.g., s3://my-bucket/path/to/pull_secret.json).
    Type: String
    Default: "s3://cp4d-ocp-cloudformation-dev/pull-secrets/pull_secret.json"    
  OpenshiftVersion:
    Description: Choose Openshift Version
    Type: String
    Default: "4.12.32"
  EnableFips:
    Description: Enable Fips for Openshift
    Type: String
    AllowedValues:
      - "false"
      - "true"
    Default: "false"
  MasterInstanceType:
    Default: m5.xlarge
    AllowedValues:
      - m5.xlarge
      - m5.2xlarge
      - m5d.xlarge
      - m5d.2xlarge
    ConstraintDescription: Must contain valid instance type
    Description: The EC2 instance type for the OpenShift master instances.
    Type: String
  MasterVolumeIOPS:
    Default: 2000
    Description: The ControlPlane volume input/output operation per seconds. For more details, refer AWS documentation
    ConstraintDescription: Must contain Integer value
    Type: Number
  MasterVolumeSize:
    Default: 200
    Description: The ControlPlace volume size
    ConstraintDescription: Must contain Integer value
    Type: Number
  MasterVolumeType:
    Default: gp3
    Type: String
    Description: The ControlPlace volume type.
    AllowedValues:
      - gp3
      - gp2
      - io1
      - io2
  WorkerInstanceType:
    Default: m5.4xlarge
    AllowedValues:
      - m5.4xlarge
      - m5.8xlarge
      - m5.12xlarge
      - m5.24xlarge
      - m5a.4xlarge
      - m5a.8xlarge
      - m5a.12xlarge
      - m5a.24xlarge
      - c5.4xlarge
      - c5.9xlarge
      - c5.12xlarge
      - c5.18xlarge
      - c5.24xlarge
      - r5.4xlarge
      - r5.9xlarge
      - r5.12xlarge
      - r5.18xlarge
      - r5.24xlarge
    ConstraintDescription: Must contain valid instance type
    Description: The EC2 instance type for the OpenShift worker instances.
    Type: String
  WorkerVolumeIOPS:
    Default: 2000
    Description: The worker volume input/output operation per seconds. For more details, refer AWS documentation
    ConstraintDescription: Must contain Integer value
    Type: Number
  WorkerVolumeSize:
    Default: 200
    Description: The worker volume size
    ConstraintDescription: Must contain Integer value
    Type: Number
  WorkerVolumeType:
    Default: gp3
    Type: String
    Description: The worker volume type.
    AllowedValues:
      - gp3
      - gp2
      - io1
      - io2
  WorkerCount:
    Default: '3'
    Description: The desired capacity for the OpenShift worker. Minimum of 3 nodes required. If the number of worker instances exceeds your Red Hat entitlement limits or AWS instance limits, the stack will fail. Choose a number that is within your limits.
    Type: Number
  OcsInstanceType:
    Description: The EC2 instance type for the OCS/ODF cluster instances.
    Default: m5.4xlarge
    Type: String
    AllowedValues:
      - m5.4xlarge
      - m5.8xlarge
      - m5.12xlarge
      - m5.24xlarge
  OcsIOPS:
    Default: 2000
    Description: The OCS instance volume input/output operation per seconds. For more details, refer AWS documentation
    ConstraintDescription: Must contain Integer value
    Type: Number
  OcsVolumeSize:
    Default: 200
    Description: The OCS instance volume size
    ConstraintDescription: Must contain Integer value
    Type: Number
  OcsVolumeType:
    Default: gp3
    Type: String
    Description: The OCS instance volume type.
    AllowedValues:
      - gp3
      - gp2
      - io1
      - io2
  NumberOfAZs:  
    Default: 3
    Description: >-
      The number of Availability Zones to be used for the deployment. Keep in mind that some regions may be limited to two Availability Zones. For a cluster to be highly available, three Availability Zones are needed to avoid a single point of failure.
    Type: Number
    AllowedValues:
    - 1
    - 3  
  AvailabilityZones:
    Description: The list of Availability Zones to use for the subnets in the VPC. The Template uses one or three Availability Zones and preserves the logical order you specify.
    Type: List<AWS::EC2::AvailabilityZone::Name>
    Default: us-east-2a,us-east-2b,us-east-2c
  VPCID:
    Description: The ID of your existing VPC for deployment.
    Type: AWS::EC2::VPC::Id
    Default: vpc-03738f32953df603f
  PrivateSubnet1ID:
    Description: The ID of the private subnet in Availability Zone A for the workload (e.g., subnet-a0246dcd).
    Type: String
    Default: "subnet-05c7d2d610d4db25f"
  PrivateSubnet2ID:
    Description: The ID of the private subnet in Availability Zone B for the workload (e.g., subnet-b1f432cd).
    Type: String
    Default: "subnet-015bca0698e9b4c41"
  PrivateSubnet3ID:
    Description: The ID of the private subnet in Availability Zone C for the workload (e.g., subnet-b1f4a2cd).
    Type: String
    Default: "subnet-03ed7835a97324708"
  PublicSubnet1ID:
    Description: The ID of the public subnet in Availability Zone A for the ELB load balancer (e.g., subnet-9bc642ac).
    Type: String
    Default: "subnet-068bc9661bea107d1"
  PublicSubnet2ID:
    Description: The ID of the public subnet in Availability Zone B for the ELB load balancer (e.g., subnet-e3246d8e).
    Type: String
    Default: "subnet-05a6043f88f7c2461"
  PublicSubnet3ID:
    Description: The ID of the public subnet in Availability Zone C for the ELB load balancer (e.g., subnet-e324ad8e).
    Type: String
    Default: "subnet-0a3646c21243f87f9"
  BootNodeAccessCIDR:
    AllowedPattern: ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\/([0-9]|[1-2][0-9]|3[0-2]))$
    ConstraintDescription: CIDR block parameter must be in the form x.x.x.x/x
    Description: The CIDR IP range that is permitted to access boot node instance. We recommend that you set this value to a trusted IP range. The value `0.0.0.0/0` permits all IP addresses to access. Additional values can be added post-deployment from the Amazon EC2 console.
    Type: String
    Default: 0.0.0.0/0
  KeyPairName:
    Description: The name of an existing public/private key pair, which allows you
      to securely connect to your instance after it launches.
    Type: AWS::EC2::KeyPair::KeyName
  ClusterNetworkCIDR:
    AllowedPattern: ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\/([0-9]|[1-2][0-9]|3[0-2]))$
    ConstraintDescription: CIDR block parameter must be in the form x.x.x.x/16-28
    Default: 10.128.0.0/14
    Description: The Cluster Network CIDR IP range that is used as IP address pools for pods.
    Type: String
  ClusterNetowrkHostPrefix:
    Description: Cluster network host prefix.
    Type: Number
    Default: 23    
  MachineNetworkCIDR:
    AllowedPattern: ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\/(1[6-9]|2[0-8]))$
    ConstraintDescription: CIDR block parameter must be in the form x.x.x.x/16-28
    Default: 10.0.0.0/16
    Description: The CIDR block of the existing VPC. It must be match for subnets
    Type: String
  ServiceNetworkCIDR: 
    AllowedPattern: ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\/([0-9]|[1-2][0-9]|3[0-2]))$
    Description: The service network CIDR IP range.
    Type: String
    Default: 172.30.0.0/16    
      
Mappings:
  AWSAMIRegionMap:
    us-east-1:
      BootNodeAmiId: ami-06640050dc3f556bb
      OCSAmiId: ami-03d1c2cba04df838c
    us-east-2:
      BootNodeAmiId: ami-092b43193629811af
      OCSAmiId: ami-0ddab715d6b88a315
    us-west-1:
      BootNodeAmiId: ami-0186e3fec9b0283ee
      OCSAmiId: ami-09b797de07577bf33
    us-west-2:
      BootNodeAmiId: ami-08970fb2e5767e3b8
      OCSAmiId: ami-0617611237b58ac93
    ap-south-1:
      BootNodeAmiId: ami-05c8ca4485f8b138a
      OCSAmiId: ami-08dfa06820a4fb482
    ap-northeast-3:
      BootNodeAmiId: ami-044921b7897a7e0da
      OCSAmiId: ami-0591a1337ebe93646
    ap-northeast-2:
      BootNodeAmiId: ami-06c568b08b5a431d5
      OCSAmiId: ami-0adf87370198caaed
    ap-southeast-1:
      BootNodeAmiId: ami-051f0947e420652a9
      OCSAmiId: ami-05345a132d89bd2b6
    ap-southeast-2:
      BootNodeAmiId: ami-0808460885ff81045
      OCSAmiId: ami-00274925d47c6e015
    ap-northeast-1:
      BootNodeAmiId: ami-0f903fb156f24adbf
      OCSAmiId: ami-09cc1da8a6fa42c4e
    ca-central-1:
      BootNodeAmiId: ami-0c3d3a230b9668c02
      OCSAmiId: ami-0baeff23c4cc6ddf5
    eu-central-1:
      BootNodeAmiId: ami-0e7e134863fac4946
      OCSAmiId: ami-083ab4c282bac44b5
    eu-west-1:
      BootNodeAmiId: ami-0f0f1c02e5e4d9d9f
      OCSAmiId: ami-07323d56fb932c84c
    eu-west-2:
      BootNodeAmiId: ami-035c5dc086849b5de
      OCSAmiId: ami-0cabefac75acfd8e3
    eu-west-3:
      BootNodeAmiId: ami-0460bf124812bebfa
      OCSAmiId: ami-01f9af256e3213df9
    eu-north-1:
      BootNodeAmiId: ami-06a2a41d455060f8b
      OCSAmiId: ami-0791daa430c70ff09
    sa-east-1:
      BootNodeAmiId: ami-0c1b8b886626f940c
      OCSAmiId: ami-0dd8411ece8c06dae
    ap-east-1:
      BootNodeAmiId: ami-011a403f2a9b2c39f
      OCSAmiId: ami-03ac23c984c812cb4

Rules: 
  SubnetsInVPC:
    Assertions:
      - Assert: !EachMemberIn
          - !ValueOfAll
            - AWS::EC2::Subnet::Id
            - VpcId
          - !RefAll 'AWS::EC2::VPC::Id'
        AssertDescription: All subnets must in the VPC      
Conditions:
  3AZCondition: !Equals [!Ref NumberOfAZs, 3]
Resources:
  OCSKMSKey:
    Type: 'AWS::KMS::Key'
    Properties:
      Description: OCS KMS key
      Enabled: True
      EnableKeyRotation: False
      KeySpec: SYMMETRIC_DEFAULT
      KeyUsage: ENCRYPT_DECRYPT
      PendingWindowInDays: 7

  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
        - arn:aws:iam::aws:policy/AdministratorAccess        
      Path: /
      Policies:
        - PolicyName: lambda-cleanUpLambda
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - ssm:SendCommand
                  - ssm:PutParameter
                  - ssm:GetParameter
                  - ssm:DeleteParameter
                Resource:
                  - '*'
              - Effect: Allow
                Action:
                  - logs:FilterLogEvents
                Resource:
                  - '*' 

  BootNodeIamRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
        - Effect: "Allow"
          Principal:
            Service:
            - "ec2.amazonaws.com"
          Action:
          - "sts:AssumeRole"
        - Effect: "Allow"
          Principal:
            AWS:
            - Ref: AWS::AccountId
          Action:
          - "sts:AssumeRole"
      MaxSessionDuration: 43200
      Path: "/"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
        - arn:aws:iam::aws:policy/AWSCloudFormationReadOnlyAccess
        - arn:aws:iam::aws:policy/AdministratorAccess        
      Policies:
      - PolicyName: bootnode-policy
        PolicyDocument:
          Version: "2012-10-17"
          Statement:
          - Effect: "Allow"
            Action: "ec2:Describe*"
            Resource: "*"
          - Effect: "Allow"
            Action: "ec2:AttachVolume"
            Resource: "*"
          - Effect: "Allow"
            Action: "ec2:DetachVolume"
            Resource: "*"
          - Effect: "Allow"
            Action: "route53:*"
            Resource: "*"
          - Effect: "Allow"
            Action:
            - "secretsmanager:GetSecretValue"
            - "secretsmanager:UpdateSecret"
            - "secretsmanager:CreateSecret"
            Resource: "*"
          - Effect: Allow
            Action:
            - ssm:SendCommand
            - ssm:PutParameter
            - ssm:GetParameter
            Resource:
            - '*'  

  BootnodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: "/"
      Roles:
      - Ref: "BootNodeIamRole"

  BootnodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Cluster Bootnode Security Group
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: !Ref BootNodeAccessCIDR
      VpcId: !Ref VPCID

  BootnodeInstance:
    Type: AWS::EC2::Instance
    Metadata:
      AWS::CloudFormation::Init:
        configSets:
          Required:
            - StackPropertiesFile
        StackPropertiesFile:
          files:
            /root/mystack.props:
              content: !Sub |
                AWS_REGION=${AWS::Region}
                AWS_STACKID="${AWS::StackId}"
                AWS_STACKNAME="${AWS::StackName}"
              mode: '000644'
              owner: root
              group: root
            /home/ec2-user/destroy.sh:
              content: !Sub |
                echo "$1 - Destroy"
                export HOME=/home/ec2-user
                cd $HOME/installer
                sudo openshift-install destroy cluster > $HOME/destroy.log
                echo "Destroy completed"
                aws ssm put-parameter --name $1"_CleanupStatus" --type "String" --value "READY" --overwrite
              mode: '000755'
              owner: root
              group: root
            /root/.aws/config:
              content: !Sub |
                [default]
                region=${AWS::Region}
              mode: '000600'
              owner: root
              group: root

    Properties:
      KeyName: !Ref 'KeyPairName'
      ImageId: !FindInMap [AWSAMIRegionMap, !Ref "AWS::Region", BootNodeAmiId]
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: 50
            VolumeType: gp3  
      IamInstanceProfile: !Ref BootnodeInstanceProfile
      Tags:
        - Key: Name
          Value: 
            !Sub
            - "${ClusterName}-bootnode"
            - ClusterName: !Ref ClusterName 
      InstanceType: t3.large 
      NetworkInterfaces:
      - GroupSet:
        - !Ref BootnodeSecurityGroup
        AssociatePublicIpAddress: true
        DeviceIndex: '0'
        DeleteOnTermination: true
        SubnetId: !Ref PublicSubnet1ID  
      UserData:
        Fn::Base64:
          !Sub 
          - |
            #!/bin/bash -x
            
            #Added the next 5 lines to include required tools for the installation of CP4D
            yum update -y
            yum install -y git podman wget jq python3.11 unzip
            podman version

            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            ./aws/install &> /var/log/userdata.awscli_install.log

            git clone https://github.com/aws-quickstart/quickstart-linux-utilities.git
            sed -i "s/aws-cfn-bootstrap-latest.tar.gz/aws-cfn-bootstrap-py3-latest.tar.gz/g" /quickstart-linux-utilities/quickstart-cfn-tools.source 
            export P=/quickstart-linux-utilities/quickstart-cfn-tools.source
            source $P
            
            qs_bootstrap_pip || qs_err " pip bootstrap failed "
            qs_aws-cfn-bootstrap || qs_err "cfn bootstrap failed"
            
            #pip3 install awscli  &> /var/log/userdata.awscli_install.log || qs_err " awscli install failed "
            /usr/local/bin/cfn-init -v --stack ${AWS::StackName} --resource BootnodeInstance --configsets Required --region ${AWS::Region}
            sudo cp /usr/local/bin/aws /usr/bin/aws

            cd /tmp
            qs_retry_command 10 wget https://s3-us-west-1.amazonaws.com/amazon-ssm-us-west-1/latest/linux_amd64/amazon-ssm-agent.rpm
            qs_retry_command 10 yum install -y ./amazon-ssm-agent.rpm
            systemctl start amazon-ssm-agent
            systemctl enable amazon-ssm-agent
            rm -f ./amazon-ssm-agent.rpm

            wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
            chmod a+x /usr/local/bin/yq

            wget https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/${OpenshiftVersion}/openshift-install-linux-${OpenshiftVersion}.tar.gz
            tar -xvzf openshift-install-linux-${OpenshiftVersion}.tar.gz
            cp openshift-install /usr/local/bin/
            cp openshift-install /usr/bin/

            wget https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/${OpenshiftVersion}/openshift-client-linux-${OpenshiftVersion}.tar.gz
            tar -xvzf openshift-client-linux-${OpenshiftVersion}.tar.gz
            cp oc /usr/local/bin/
            cp oc /usr/bin/
            cp kubectl /usr/local/bin/
            cp kubectl /usr/bin/

            export ICPDInstallationCompletedURL='${ICPDInstallationCompletedHandle}'
            export AWS_REGION=${AWS::Region}
            export AWS_STACKID=${AWS::StackId}
            export AWS_STACKNAME=${AWS::StackName}

            # Installing OpenShift
            export HOME=/home/ec2-user
            cd $HOME

            # change mode of destroy script
            chmod +x $HOME/destroy.sh

            # generate public key
            ssh-keygen -t rsa -b 4096 -f $HOME/.ssh/id_rsa -q -N ""
            
            # configure installer
            mkdir -p installer
            cd installer

            # copy pull-secret from S3
            aws s3 cp ${RedhatPullSecret} pull-secret

            export RELEASE_IMAGE=$(openshift-install version | awk '/release image/ {print $3}')
            echo $RELEASE_IMAGE

            export CCO_IMAGE=$(oc adm release info --image-for='cloud-credential-operator' $RELEASE_IMAGE)
            echo $CCO_IMAGE

            oc image extract $CCO_IMAGE --file="/usr/bin/ccoctl" -a ./pull-secret
            chmod 755 ccoctl
            cp ccoctl /usr/local/bin/
            cp ccoctl /usr/bin/

            mkdir -p credreqs
            oc adm release extract --cloud=aws --credentials-requests $RELEASE_IMAGE --to=./credreqs

            # Create install-config.yaml
            yq '.apiVersion = "v1"' install-config.yaml > install-config.yaml
            yq -i ".baseDomain = \"${DomainName}\"" install-config.yaml
            yq -i '.credentialsMode = "Manual"' install-config.yaml

            # Create compute node
            yq -i '.compute[0].architecture = "amd64"' install-config.yaml
            yq -i '.compute[0].hyperthreading = "Enabled"' install-config.yaml
            yq -i '.compute[0].name = "worker"' install-config.yaml
            yq -i ".compute[0].platform.aws.rootVolume.iops = ${WorkerVolumeIOPS}" install-config.yaml
            yq -i ".compute[0].platform.aws.rootVolume.size = ${WorkerVolumeSize}" install-config.yaml
            yq -i ".compute[0].platform.aws.rootVolume.type = \"${WorkerVolumeType}\"" install-config.yaml
            yq -i ".compute[0].platform.aws.type = \"${WorkerInstanceType}\"" install-config.yaml

            # add compute zone for worker
            if [ "${MultiAZ}" == "True" ]; then
              yq -i ".compute[0].platform.aws.zones += [ \"${AvailabilityZone1}\",\"${AvailabilityZone2}\",\"${AvailabilityZone3}\" ]" install-config.yaml
            else
              yq -i ".compute[0].platform.aws.zones += [ \"${AvailabilityZone1}\" ]" install-config.yaml
            fi

            # add worker node count
            yq -i ".compute[0].replicas = ${WorkerCount}" install-config.yaml

            # control plane
            yq -i '.controlPlane.architecture = "amd64"' install-config.yaml
            yq -i '.controlPlane.hyperthreading = "Enabled"' install-config.yaml
            yq -i '.controlPlane.name = "master"' install-config.yaml

            # add compute zone for master
            if [ "${MultiAZ}" == "True" ]; then
              yq -i ".controlPlane.platform.aws.zones += [ \"${AvailabilityZone1}\",\"${AvailabilityZone2}\",\"${AvailabilityZone3}\" ]" install-config.yaml
            else
              yq -i ".controlPlane.platform.aws.zones += [ \"${AvailabilityZone1}\" ]" install-config.yaml
            fi
            
            yq -i ".controlPlane.platform.aws.rootVolume.iops = ${MasterVolumeIOPS}" install-config.yaml
            yq -i ".controlPlane.platform.aws.rootVolume.size = ${MasterVolumeSize}" install-config.yaml
            yq -i ".controlPlane.platform.aws.rootVolume.type = \"${MasterVolumeType}\"" install-config.yaml
            yq -i ".controlPlane.platform.aws.type = \"${MasterInstanceType}\"" install-config.yaml

            # metadata
            yq -i ".metadata.name = \"${ClusterName}\"" install-config.yaml

            # networking
            yq -i ".networking.clusterNetwork[0].cidr = \"${ClusterNetworkCIDR}\"" install-config.yaml
            yq -i ".networking.clusterNetwork[0].hostPrefix = ${ClusterNetowrkHostPrefix}" install-config.yaml

            yq -i ".networking.machineNetwork[0].cidr = \"${MachineNetworkCIDR}\"" install-config.yaml
            yq -i '.networking.networkType = "OpenShiftSDN"' install-config.yaml

            yq -i ".networking.serviceNetwork[0] = \"${ServiceNetworkCIDR}\"" install-config.yaml

            yq -i ".platform.aws.region = \"${AWS::Region}\"" install-config.yaml

            # add subnet
            if [ "${MultiAZ}" == "True" ]; then
              if [ "${PrivateCluster}" == "True" ]; then
                yq -i ".platform.aws.subnets += [ \"${PrivateSubnet1ID}\",\"${PrivateSubnet2ID}\",\"${PrivateSubnet3ID}\" ]" install-config.yaml
              else
                yq -i ".platform.aws.subnets += [ \"${PrivateSubnet1ID}\",\"${PrivateSubnet2ID}\",\"${PrivateSubnet3ID}\",\"${PublicSubnet1ID}\",\"${PublicSubnet2ID}\",\"${PublicSubnet3ID}\" ]" install-config.yaml
              fi
            else
              if [ "${PrivateCluster}" == "True" ]; then
                yq -i ".platform.aws.subnets += [ \"${PrivateSubnet1ID}\" ]" install-config.yaml
              else
                yq -i ".platform.aws.subnets += [ \"${PrivateSubnet1ID}\",\"${PublicSubnet1ID}\" ]" install-config.yaml
              fi
            fi

            yq -i ".fips = ${EnableFips}" install-config.yaml

            # sshkey
            export SSHKEY=`cat $HOME/.ssh/id_rsa.pub`
            yq -i ".sshKey = \"$SSHKEY\"" install-config.yaml

            # pull-secret
            yq -i '.pullSecret = "|PULLSECRET|"' install-config.yaml
            export PULLSECRET=`cat $HOME/installer/pull-secret`
            sed -i 's#|PULLSECRET|#'$PULLSECRET'#g' install-config.yaml

            if [ "${PrivateCluster}" == "True" ]; then
              yq -i '.publish = "Internal"' install-config.yaml
            else
              yq -i '.publish = "External"' install-config.yaml
            fi            

            cp install-config.yaml /tmp/

            # generate openshift manifest
            openshift-install create manifests

            # generate IAM roles, ServiceAccount and OIDC
            ccoctl aws create-all --name ${ClusterName} --region ${AWS::Region} --credentials-requests-dir ./credreqs --output-dir _output

            cp _output/manifests/* manifests/
            cp -a _output/tls .

            openshift-install create cluster --log-level=debug
            chown -R ec2-user:ec2-user $HOME/installer


            ## OCS
            mkdir -p $HOME/ocs

            export KUBECONFIG=$HOME/installer/auth/kubeconfig
            export CLUSTERID=$(oc get machineset -n openshift-machine-api -o jsonpath='{.items[0].metadata.labels.machine\.openshift\.io/cluster-api-cluster}')
            export OCSKMSKEYARN="${OCSKMSKeyArn}"
            export OCSINSTANCETYPE=${OcsInstanceType}
            export OCSIOPS=${OcsIOPS}
            export OCSVOLSIZE=${OcsVolumeSize}
            export OCSVOLTYPE=${OcsVolumeType}
            
            wget -P $HOME/ocs/ https://ibm-aws-immersion-day.s3.us-east-2.amazonaws.com/cloudformation/openshift/config/ocs-prereqs.sh
            wget -P $HOME/ocs/ https://ibm-aws-immersion-day.s3.us-east-2.amazonaws.com/cloudformation/openshift/config/1_ocs_olm.yaml
            wget -P $HOME/ocs/ https://ibm-aws-immersion-day.s3.us-east-2.amazonaws.com/cloudformation/openshift/config/2_ocs_storagecluster.yaml
            wget -P $HOME/ocs/ https://ibm-aws-immersion-day.s3.us-east-2.amazonaws.com/cloudformation/openshift/config/3_ocs_toolbox.yaml
            wget -P $HOME/ocs/ https://ibm-aws-immersion-day.s3.us-east-2.amazonaws.com/cloudformation/openshift/config/4_ocs_machineset_template.yaml

            echo "Cluster ID $CLUSTERID"
            echo "Availability Zone $AvailabilityZone1}  ${AvailabilityZone2}  ${AvailabilityZone3}"
            echo "OCSAMIID  ${OCSAMIID}"
            echo "OCSIOPS  $OCSIOPS"
            echo "OCSVOLSIZE $OCSVOLSIZE"
            echo "OCSVOLTYPE $OCSVOLTYPE"
            echo "OCSINSTANCETYPE  $OCSINSTANCETYPE"
            echo "Private Subnets ${PrivateSubnet1ID} ${PrivateSubnet2ID} ${PrivateSubnet3ID}"
            echo "OCSKMSKeyArn ${OCSKMSKeyArn}"

            echo "Creating machinesets"
            cp $HOME/ocs/4_ocs_machineset_template.yaml $HOME/ocs/ocs_a.yaml
            sed -i 's/|CLUSTERID|/'$CLUSTERID'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's/|ZONE|/'${AvailabilityZone1}'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's/|OCSAMIID|/'${OCSAMIID}'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's/|OCSIOPS|/'$OCSIOPS'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's/|OCSVOLSIZE|/'$OCSVOLSIZE'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's/|OCSVOLTYPE|/'$OCSVOLTYPE'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's/|OCSINSTANCETYPE|/'$OCSINSTANCETYPE'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's/|AWSREGION|/'${AWS::Region}'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's/|SUBNET|/'${PrivateSubnet1ID}'/g' $HOME/ocs/ocs_a.yaml
            sed -i 's#|OCSKMSKEYARN|#'${OCSKMSKeyArn}'#g' $HOME/ocs/ocs_a.yaml 
            oc create -f $HOME/ocs/ocs_a.yaml

            
            if [ "${MultiAZ}" == "True" ]; then
              cp $HOME/ocs/4_ocs_machineset_template.yaml $HOME/ocs/ocs_b.yaml
              sed -i 's/|CLUSTERID|/'$CLUSTERID'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's/|ZONE|/'${AvailabilityZone2}'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's/|OCSAMIID|/'${OCSAMIID}'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's/|OCSIOPS|/'$OCSIOPS'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's/|OCSVOLSIZE|/'$OCSVOLSIZE'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's/|OCSVOLTYPE|/'$OCSVOLTYPE'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's/|OCSINSTANCETYPE|/'$OCSINSTANCETYPE'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's/|AWSREGION|/'${AWS::Region}'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's/|SUBNET|/'${PrivateSubnet2ID}'/g' $HOME/ocs/ocs_b.yaml
              sed -i 's#|OCSKMSKEYARN|#'${OCSKMSKeyArn}'#g' $HOME/ocs/ocs_b.yaml
              oc create -f $HOME/ocs/ocs_b.yaml

              cp $HOME/ocs/4_ocs_machineset_template.yaml $HOME/ocs/ocs_c.yaml
              sed -i 's/|CLUSTERID|/'$CLUSTERID'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's/|ZONE|/'${AvailabilityZone3}'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's/|OCSAMIID|/'${OCSAMIID}'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's/|OCSIOPS|/'$OCSIOPS'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's/|OCSVOLSIZE|/'$OCSVOLSIZE'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's/|OCSVOLTYPE|/'$OCSVOLTYPE'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's/|OCSINSTANCETYPE|/'$OCSINSTANCETYPE'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's/|AWSREGION|/'${AWS::Region}'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's/|SUBNET|/'${PrivateSubnet3ID}'/g' $HOME/ocs/ocs_c.yaml
              sed -i 's#|OCSKMSKEYARN|#'${OCSKMSKeyArn}'#g' $HOME/ocs/ocs_c.yaml
              oc create -f $HOME/ocs/ocs_c.yaml
            fi

            echo "Sleeping for 5 mins to get change reflect"
            sleep 300

            /bin/bash $HOME/ocs/ocs-prereqs.sh
            
            echo "Creating OCS OLM"
            oc create -f $HOME/ocs/1_ocs_olm.yaml
            echo "Sleeping for 5 mins to get change reflect"
            sleep 300

            echo "Creating OCS Storage cluster"
            oc create -f $HOME/ocs/2_ocs_storagecluster.yaml
            echo "Sleeping for 5 mins to get change reflect"
            sleep 300

            echo "Creating OCS toolbox"
            oc create -f $HOME/ocs/3_ocs_toolbox.yaml
            echo "Sleeping for 5 mins to get change reflect"
            sleep 300

            oc get pods -n openshift-storage

            ecode=$?
            /usr/local/bin/cfn-signal --exit-code $ecode --id $AWS_STACKID  --data "See logs at $HOME/cpd-status/log/" $ICPDInstallationCompletedURL
          -
            MultiAZ: !If [ 3AZCondition , 'True', 'False']
            AvailabilityZone1: !Select [0, !Ref AvailabilityZones]
            AvailabilityZone2: !If [ 3AZCondition, !Select [1, !Ref AvailabilityZones], ""]
            AvailabilityZone3: !If [ 3AZCondition, !Select [2, !Ref AvailabilityZones], ""]
            OCSKMSKeyArn: !GetAtt 'OCSKMSKey.Arn'
            OCSAMIID: !FindInMap [AWSAMIRegionMap, !Ref "AWS::Region", OCSAmiId]
           
  CleanUpLambda:
    Type: AWS::Lambda::Function
    Properties:
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse
          import os
          import traceback
          import time
          def handler(event, context):
              responseData = {}
              try:
                  print("event_obj:",json.dumps(event))
                  print(event['RequestType'])
                  if event['RequestType'] == 'Delete':
                    print("Run unsubscribe script")
                    ssm = boto3.client('ssm',region_name=os.environ['Region'])
                    instanceID = os.environ['BootNode']
                    stackname = os.environ['StackName']
                    print(instanceID)
                    response = ssm.send_command(Targets=[{"Key":"instanceids","Values":[instanceID]}],
                            DocumentName="AWS-RunShellScript",
                            Parameters={"commands":["/home/ec2-user/destroy.sh %s" %(stackname)],
                                        "executionTimeout":["1200"],
                                        "workingDirectory":["/home/ec2-user"]},
                            Comment="Execute script in uninstall openshift",
                            TimeoutSeconds=120)
                    print(response)
                    current_status = "WAIT"
                    final_status = "READY"
                    parameterName = stackname+"_CleanupStatus"           
                    response = ssm.put_parameter(Name=parameterName,
                           Description="Waiting for CleanupStatus to be READY",
                           Value=current_status,
                           Type='String',
                           Overwrite=True)        
                    print(response)    
                    while(current_status!=final_status):
                      time.sleep(30) 
                      response = ssm.get_parameter(Name=parameterName)
                      parameter = response.get('Parameter')
                      current_status = parameter.get('Value')
                      print(current_status)
                    ssm.delete_parameter(Name=parameterName)    
              except Exception as e:
                print(e)
                traceback.print_exc()
              cfnresponse.send(event, context, cfnresponse.SUCCESS, {}, '')
      Environment:
        Variables:
          Region: !Ref AWS::Region
          BootNode: !Ref BootnodeInstance
          StackName: !Ref AWS::StackName
      Handler: index.handler
      Role: !GetAtt 'LambdaExecutionRole.Arn'
      Runtime: python3.8
      Timeout: 600
             
  Cleanup :
    Type: Custom::Cleanup
    Properties:
      DependsOn: BootnodeInstance
      ServiceToken: !GetAtt 'CleanUpLambda.Arn'
 
  ICPDInstallationCompletedHandle:
    Type: AWS::CloudFormation::WaitConditionHandle  

  ICPDInstallationCompleted:
    Type: AWS::CloudFormation::WaitCondition
    Properties:
      Count: 1
      Handle: !Ref ICPDInstallationCompletedHandle
      Timeout: '40000'  

Outputs:
  BootnodeInstanceId:
    Description: Bootnode Instance ID.
    Value: !Ref BootnodeInstance

  BootnodePublicIp:
    Description: The boot node public IP address.
    Value: !GetAtt BootnodeInstance.PublicIp
